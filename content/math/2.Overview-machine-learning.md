---
title: "Overview machine learning"
date: 2021-08-30T14:57:52+07:00
description: AHIHI
toc: true # Table of content
mermaid: true
math: true
categories: ["Math for Machine learning", "Machine learning"]
---

The biggest problem for people who study about machine learning is the mathematical foundation under machine learning surface. Actually, we can learn math for ML before getting into machine learning area, but It is very boring because you don't see how math theory work in machine learning. Only onething you find that It's is just like classical math classroom which sitting in high school. Therefore, how we build a strong mathematical foundation and still affair about classical theory ? 

My teacher have many course about Math for Computer Science in my university and one day his student from class said that: "I don't know anything you teach me. I suppose to change my major, not Computer Science." But, you can break the scare by reading about basic machine learning before step into math. It will give a quite good picture and also build a confident for you. When you already face to mathematica foundation of machine learning, you will cognitive meanings of theory terms, algrithms you read before. This is simple idea that I think you can try.

In this article, we will traverse machine learning picture. Detailly, we will define What is Machine learning ?, Essential tasks: Supervised Learning, Unsupervised learning, Reinforcement Learning and important keyword throughout a machine learning problem. 


## 1. What is Machine learning ?
----
A popular definition of machine learning (ML) stated by Tom Mitchell as follow:

> A computer program is said to learn from experience E with respect to some class of task T, and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

In that, terms can be defined like bellow:
- T: predifined task we wish the system to learn.
- P: evaluate the system to measure how it good.
- E: nature of the training signal or experience we provide for system.

When dealing with a machine learning problem we need define cleverly these terms. For example, we have a dataset that images contain netheir apple or pear and our purpose is want to build a program can automaticly classify the apple or pear appearing in input image using machine learning. In this case, we can seperate the problem into T, P, E terms like bellow:
- T: image classification, recieve image input and return the name of fruit is apple or pear.
- P: the number of correct images over the entire predictions. For example, our system predict exactly 7 images on 10 images in total, then accuracy will calculated by $7 / 10 = 0.7$.
- E: the images we have, espectially it is a set of image, each image labeled tag either apple or pear.

--- image ----

Almost all of machine learning can be viewed in probabilistic term, making probabilistic thinkking fundamental. It is just one of direction you can folllow. But we can connect what we do in machine learning to every computatinal science, whether that be in stochastic optimization, control theory, operations research, econometrics, information theory, statistical physics or bio-statistics. For this reason, mastery of probabilictic thinking is essential.


## 2. Suppervised learning
---
The most common type of ML tasks is **supervised learning**. In this problem, the task T is to learn a mapping $f$ from inputs $x \in X$ to outputs $y \in Y$.

$$ f: x \rightarrow y $$

The function $f$ is represented by a set of parameters $\theta$ which learned from training data - experience $E$ is given in the form of a set of $N$ input-output pairs $\{\(x_n, y_n\)\}_{n=1}^{N}$. The inputs $x$ also called the features or predictors.The output $y$ is also known as the **label**, **target**, or **response**. N is called **sample size**.

### 2.1 Classification



### 2.2 Regression




## 3. Unsupervised learning
---


## 4. Reinformance learning
---


## 5. Overfitting and generalization
---

## 6. No free lunch theorem
----